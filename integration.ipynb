{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364fe31-f4d2-4b41-8c61-fef5b4eb5b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e4b18a5273459dbf8aa81919b91130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='240', width='320'), Image(value=b'', format='jpeg', heiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from action_package import ROBOT\n",
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "import threading\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import deque\n",
    "\n",
    "# Global state variable\n",
    "action_in_progress = threading.Event()  # Use event objects to mark whether an action is being performed\n",
    "\n",
    "# Initializing robot\n",
    "robot = ROBOT()\n",
    "\n",
    "speed = 40\n",
    "\n",
    "# Obstacle avoidance sensor configuration\n",
    "SensorRight = 16\n",
    "SensorLeft = 12\n",
    "TRIG = 20\n",
    "ECHO = 21\n",
    "\n",
    "# Camera configuration\n",
    "cam = cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "cam.set(3, 320)  # width\n",
    "cam.set(4, 240)  # height\n",
    "\n",
    "# Obstacle avoidance correlation function\n",
    "def setup_sensors():\n",
    "    GPIO.setwarnings(False)\n",
    "    GPIO.setmode(GPIO.BCM)\n",
    "    GPIO.setup(SensorRight, GPIO.IN)\n",
    "    GPIO.setup(SensorLeft, GPIO.IN)\n",
    "    GPIO.setup(TRIG, GPIO.OUT)\n",
    "    GPIO.setup(ECHO, GPIO.IN)\n",
    "\n",
    "def get_distance():\n",
    "    \"\"\"Get the distance of the ultrasonic sensor\"\"\"\n",
    "    GPIO.output(TRIG, 0)\n",
    "    time.sleep(0.000002)\n",
    "    GPIO.output(TRIG, 1)\n",
    "    time.sleep(0.00001)\n",
    "    GPIO.output(TRIG, 0)\n",
    "\n",
    "    while GPIO.input(ECHO) == 0:\n",
    "        pass\n",
    "    start_time = time.time()\n",
    "\n",
    "    while GPIO.input(ECHO) == 1:\n",
    "        pass\n",
    "    end_time = time.time()\n",
    "\n",
    "    distance = (end_time - start_time) * 340 / 2 * 100\n",
    "    time.sleep(0.02)\n",
    "    return round(distance, 2)\n",
    "\n",
    "# Convert image to JPEG format\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "# Initializes the display area\n",
    "FGmaskComp_img = widgets.Image(format='jpeg', width=320, height=240)\n",
    "frame_img = widgets.Image(format='jpeg', width=320, height=240)\n",
    "display(widgets.HBox([FGmaskComp_img, frame_img]))\n",
    "\n",
    "# Obstacle avoiding thread\n",
    "obstacle_event = threading.Event()\n",
    "gesture_event = threading.Event()\n",
    "\n",
    "def obstacle_avoidance():\n",
    "    \"\"\"Obstacle avoidance logic\"\"\"\n",
    "    setup_sensors()\n",
    "    while not obstacle_event.is_set():\n",
    "        dist = get_distance()\n",
    "        SR = GPIO.input(SensorRight)\n",
    "        SL = GPIO.input(SensorLeft)\n",
    "\n",
    "        if dist < 10 or SR == 0 or SL == 0:\n",
    "            gesture_event.set()  # Pause gesture detection\n",
    "            action_in_progress.set()  # Set the status to busy\n",
    "\n",
    "            robot.t_down(speed, 1)  # Back 1 second\n",
    "            robot.t_stop(0)      # stop\n",
    "            time.sleep(0.5)      # Delay to avoid miscontact\n",
    "\n",
    "            if SL == 0:\n",
    "                robot.turnRight(speed, 0.5)  # Turn right for 0.5 seconds\n",
    "                robot.t_stop(0)\n",
    "            elif SR == 0:\n",
    "                robot.turnLeft(speed, 0.5)  # Turn left 0.5 seconds\n",
    "                robot.t_stop(0)\n",
    "\n",
    "            action_in_progress.clear()  # Clear busy state\n",
    "            gesture_event.clear()  # Recovery gesture detection\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Gesture control thread\n",
    "def detect_gesture(mask, frame):\n",
    "    \"\"\"gesture recognition\"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < 500:  # Filter for smaller Outlines\n",
    "            continue\n",
    "        \n",
    "        (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "        \n",
    "        hull = cv2.convexHull(cnt, returnPoints=False)\n",
    "        if len(hull) < 3:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            defects = cv2.convexityDefects(cnt, hull)\n",
    "            if defects is not None:\n",
    "                finger_count = 0\n",
    "                for i in range(defects.shape[0]):\n",
    "                    s, e, f, d = defects[i, 0]\n",
    "                    start = tuple(cnt[s][0])\n",
    "                    end = tuple(cnt[e][0])\n",
    "                    far = tuple(cnt[f][0])\n",
    "\n",
    "                    # calculate angle\n",
    "                    a = np.linalg.norm(np.array(start) - np.array(far))\n",
    "                    b = np.linalg.norm(np.array(end) - np.array(far))\n",
    "                    c = np.linalg.norm(np.array(start) - np.array(end))\n",
    "                    angle = np.arccos((a**2 + b**2 - c**2) / (2 * a * b)) * 57\n",
    "\n",
    "                    if angle <= 90:  # Finger detected\n",
    "                        finger_count += 1\n",
    "                        cv2.line(frame, start, far, [0, 255, 0], 2)\n",
    "                        cv2.line(frame, end, far, [0, 255, 0], 2)\n",
    "                \n",
    "                if finger_count == 1:\n",
    "                    return \"Left\"\n",
    "                elif finger_count == 2:\n",
    "                    return \"Right\"\n",
    "                elif finger_count == 3:\n",
    "                    return \"Forward\"\n",
    "                elif finger_count == 4:\n",
    "                    return \"Backward\"\n",
    "                elif finger_count == 5:\n",
    "                    return \"Stop\"\n",
    "        except cv2.error as e:\n",
    "            print(f\"Error detecting convexity defects: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def gesture_control():\n",
    "    last_gesture = None\n",
    "    last_gesture_time = time.time()  # Record the last gesture recognition time\n",
    "    gesture_delay = 5  # Set the delay time between gesture recognition (seconds)\n",
    "\n",
    "    while True:\n",
    "        if gesture_event.is_set():  # Obstacle avoidance logic is running\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        if action_in_progress.is_set():  # Action not completed, wait until complete to continue\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame from camera\")\n",
    "            continue\n",
    "\n",
    "        frame = cv2.flip(frame, 0)\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Color range (skin tone range, palm color) :\n",
    "        lower_skin = np.array([0, 20, 70], dtype=np.uint8)  # Lower bound for skin color\n",
    "        upper_skin = np.array([20, 255, 255], dtype=np.uint8)  # Upper bound for skin color\n",
    "        mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "        FGmaskComp_img.value = bgr8_to_jpeg(mask)\n",
    "        gesture = detect_gesture(mask, frame)\n",
    "\n",
    "        # Check whether the gesture recognition delay condition is met\n",
    "        current_time = time.time()\n",
    "        if gesture and gesture != last_gesture and (current_time - last_gesture_time) >= gesture_delay:\n",
    "            action_in_progress.set()  # Mark busy state\n",
    "\n",
    "            if gesture == \"Left\":\n",
    "                robot.moveLeft(speed, 1)\n",
    "            elif gesture == \"Right\":\n",
    "                robot.moveRight(speed, 1)\n",
    "            elif gesture == \"Forward\":\n",
    "                robot.t_up(speed, 3)\n",
    "            elif gesture == \"Backward\":\n",
    "                robot.t_down(speed, 3)\n",
    "            elif gesture == \"Stop\":\n",
    "                robot.t_stop(0)\n",
    "\n",
    "            # Stop when the action is complete\n",
    "            robot.t_stop(0)\n",
    "            action_in_progress.clear()  # Clear the busy state and prepare for the next action\n",
    "            last_gesture = gesture\n",
    "            last_gesture_time = current_time  # Update the time of the last recognition\n",
    "\n",
    "        frame_img.value = bgr8_to_jpeg(frame)  # Update Display\n",
    "\n",
    "    cam.release()\n",
    "\n",
    "\n",
    "# Mainline start\n",
    "try:\n",
    "    obstacle_thread = threading.Thread(target=obstacle_avoidance)\n",
    "    gesture_thread = threading.Thread(target=gesture_control)\n",
    "\n",
    "    obstacle_thread.start()\n",
    "    gesture_thread.start()\n",
    "\n",
    "    obstacle_thread.join()\n",
    "    gesture_thread.join()\n",
    "except KeyboardInterrupt:\n",
    "    obstacle_event.set()\n",
    "    gesture_event.set()\n",
    "    GPIO.cleanup()\n",
    "    cam.release()\n",
    "    print(\"Program terminated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a3234-91b4-4caf-a98f-bfd3579c11b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634b360-19d9-46a7-a602-fb52eb5f6b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
